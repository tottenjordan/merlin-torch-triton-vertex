{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24780d62-9700-4657-9f21-97ee5d3e9d3a",
   "metadata": {},
   "source": [
    "# Deploy T4Rec model on Triton-based Vertex endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67332060-f6be-441c-adc6-9b9acf0a3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd1e3c-cde1-4ff4-b900-308ad2ac0072",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47399c5a-30e3-4a85-95ca-3abc934236eb",
   "metadata": {},
   "source": [
    "### get project vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "b773bb6e-3df8-4105-8174-d66d222580d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n",
      "REGION: us-central1\n",
      "VERTEX_SA: jt-vertex-sa@hybrid-vertex.iam.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "# VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "VERTEX_SA = 'jt-vertex-sa@hybrid-vertex.iam.gserviceaccount.com'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")\n",
    "print(f\"REGION: {REGION}\")\n",
    "print(f\"VERTEX_SA: {VERTEX_SA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca752bcb-1b74-4da4-a1cf-dcc47bfa09d2",
   "metadata": {},
   "source": [
    "### get workspace vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "6417c712-eeef-4d49-9c80-9d0c206320f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_DATA_DIR: workspace/data\n",
      "TRANSFORMED_WORKFLOW: workspace/data/processed_nvt\n",
      "OUTPUT_DIR: workspace/data/sessions_by_day\n",
      "MODEL_PATH: workspace/data/saved_model\n",
      "ENSEMBLE_MODEL_PATH: workspace/data/models\n"
     ]
    }
   ],
   "source": [
    "# INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data\")\n",
    "# OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", f\"{INPUT_DATA_DIR}/sessions_by_day\")\n",
    "# model_path= os.environ.get(\"model_path\", f\"{INPUT_DATA_DIR}/saved_model\")\n",
    "\n",
    "REPO_WORKSPACE = 'workspace'\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "INPUT_DATA_DIR=f'{REPO_WORKSPACE}/{DATA_DIR}'\n",
    "TRANSFORMED_WORKFLOW=f'{INPUT_DATA_DIR}/processed_nvt'\n",
    "OUTPUT_DIR=f'{INPUT_DATA_DIR}/sessions_by_day'\n",
    "MODEL_PATH = f'{INPUT_DATA_DIR}/saved_model'\n",
    "ENSEMBLE_MODEL_PATH = f'{INPUT_DATA_DIR}/models'\n",
    "\n",
    "print(f\"INPUT_DATA_DIR: {INPUT_DATA_DIR}\")\n",
    "print(f\"TRANSFORMED_WORKFLOW: {TRANSFORMED_WORKFLOW}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"MODEL_PATH: {MODEL_PATH}\")\n",
    "print(f\"ENSEMBLE_MODEL_PATH: {ENSEMBLE_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f3ef277b-522a-49e4-9f00-d59f560ea1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mworkspace/data/models\u001b[00m\n",
      "├── \u001b[01;34m0_predictpytorchtriton\u001b[00m\n",
      "│   ├── \u001b[01;34m1\u001b[00m\n",
      "│   │   └── model.pt\n",
      "│   └── config.pbtxt\n",
      "└── \u001b[01;34mensemble_model\u001b[00m\n",
      "    ├── \u001b[01;34m1\u001b[00m\n",
      "    └── config.pbtxt\n",
      "\n",
      "4 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "!tree $ENSEMBLE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c46b7-a4de-4946-bf08-c1de1738217c",
   "metadata": {},
   "source": [
    "### set deployment version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "4cec5e1e-a8b5-47cc-a9c2-87fa74396edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION='jvt02'\n",
    "MODEL_VERSION='v03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef883b2-16c6-46cf-ad39-cbba61559dea",
   "metadata": {},
   "source": [
    "### create GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c7c5d62f-ece9-42c3-b305-9fb5f9fa4058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET_URI: gs://merlin-transformers4rec-jvt02\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME=f'merlin-transformers4rec-{VERSION}'\n",
    "BUCKET_URI=f'gs://{BUCKET_NAME}'\n",
    "\n",
    "print(f\"BUCKET_URI: {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d9477e-f963-4ec3-b26a-0fd061331c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://merlin-transformers4rec-jvt02/...\n"
     ]
    }
   ],
   "source": [
    "# ! gcloud storage buckets create $BUCKET_URI --location=$REGION --project=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc317c3b-23b7-421b-a82f-66e956e88b86",
   "metadata": {},
   "source": [
    "### copy artifact repo to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "a49eb223-fc3e-417c-bdcb-60b599ad79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud storage cp -r ./$REPO_WORKSPACE $BUCKET_URI/$MODEL_VERSION/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "86679fbf-e89c-493f-bf3c-81b28419829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://merlin-transformers4rec-jvt02/v03/workspace/data/models/\n",
      "gs://merlin-transformers4rec-jvt02/v03/workspace/data/processed_nvt/\n",
      "gs://merlin-transformers4rec-jvt02/v03/workspace/data/saved_model/\n",
      "gs://merlin-transformers4rec-jvt02/v03/workspace/data/sessions_by_day/\n",
      "gs://merlin-transformers4rec-jvt02/v03/workspace/data/workflow_etl/\n"
     ]
    }
   ],
   "source": [
    "! gcloud storage ls $BUCKET_URI/$MODEL_VERSION/workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "40ecf153-cdee-42b1-885f-83d41e23f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_ARTIFACTS_REPO_GCS: gs://merlin-transformers4rec-jvt02/v03/workspace/data/models\n",
      "WORKFLOW_REPO_GCS: gs://merlin-transformers4rec-jvt02/v03/workspace/data/workflow_etl\n"
     ]
    }
   ],
   "source": [
    "MODEL_ARTIFACTS_REPO_GCS = f\"{BUCKET_URI}/{MODEL_VERSION}/workspace/data/models\"\n",
    "WORKFLOW_REPO_GCS = f\"{BUCKET_URI}/{MODEL_VERSION}/workspace/data/workflow_etl\"\n",
    "\n",
    "print(f\"MODEL_ARTIFACTS_REPO_GCS: {MODEL_ARTIFACTS_REPO_GCS}\")\n",
    "print(f\"WORKFLOW_REPO_GCS: {WORKFLOW_REPO_GCS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0fe7b-7a93-4083-bec8-f9ec367a3e27",
   "metadata": {},
   "source": [
    "# Build Serving Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52a8cf-d643-46dc-bfdd-8412f77efb37",
   "metadata": {},
   "source": [
    "### define model, endpoint, and serving image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ffc94017-2092-44a4-9d81-73624f46bbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DISPLAY_NAME: triton-0_predictpytorchtriton-v03\n",
      "DEPLOYED_MODEL_DISPLAY_NAME: deployed-triton-0_predictpytorchtriton-v03\n",
      "ENDPOINT_DISPLAY_NAME: endpoint-0_predictpytorchtriton-jvt02\n",
      "IMAGE_URI: gcr.io/hybrid-vertex/triton-0_predictpytorchtriton-v03\n",
      "DOCKERNAME: servet4rec-tr\n"
     ]
    }
   ],
   "source": [
    "# set model names and version\n",
    "MODEL_NAME = \"0_predictpytorchtriton\"\n",
    "MODEL_DISPLAY_NAME = f\"triton-{MODEL_NAME}-{MODEL_VERSION}\"\n",
    "DEPLOYED_MODEL_DISPLAY_NAME=f\"deployed-{MODEL_DISPLAY_NAME}\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"endpoint-{MODEL_NAME}-{VERSION}\"\n",
    "\n",
    "# Docker definitions for training\n",
    "IMAGE_NAME = f'{MODEL_DISPLAY_NAME}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "DOCKERNAME='servet4rec-tr'\n",
    "\n",
    "\n",
    "print(f\"MODEL_DISPLAY_NAME: {MODEL_DISPLAY_NAME}\")\n",
    "print(f\"DEPLOYED_MODEL_DISPLAY_NAME: {DEPLOYED_MODEL_DISPLAY_NAME}\")\n",
    "print(f\"ENDPOINT_DISPLAY_NAME: {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"IMAGE_URI: {IMAGE_URI}\")\n",
    "print(f\"DOCKERNAME: {DOCKERNAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4474712-897e-4019-b6b5-dbf06e4b9bef",
   "metadata": {},
   "source": [
    "### create serving dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "57d23bd3-8a0b-40c1-b6f1-699bc29a133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "SERVING_SUB_DIR = 'serving'\n",
    "\n",
    "! rm -rf $REPO_DOCKER_PATH_PREFIX\n",
    "\n",
    "!mkdir $REPO_DOCKER_PATH_PREFIX\n",
    "!mkdir $REPO_DOCKER_PATH_PREFIX/$SERVING_SUB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "97806dae-c37c-4bd6-95fa-c8121e061dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/cloudbuild.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/cloudbuild.yaml\n",
    "\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/Dockerfile.$_DOCKERNAME']\n",
    "images:\n",
    "- '$_IMAGE_URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "064dfd22-0e31-4340-9436-f8b5b39c1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/entrypoint.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/entrypoint.sh\n",
    "#!/bin/bash\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Set up a global error handler\n",
    "err_handler() {\n",
    "    echo \"Error on line: $1\"\n",
    "    echo \"Caused by: $2\"\n",
    "    echo \"That returned exit status: $3\"\n",
    "    echo \"Aborting...\"\n",
    "    exit $3\n",
    "}\n",
    "\n",
    "trap 'err_handler \"$LINENO\" \"$BASH_COMMAND\" \"$?\"' ERR\n",
    "\n",
    "\n",
    "if [ -z \"${AIP_STORAGE_URI}\" ]\n",
    "  then\n",
    "    echo 'AIP_STORAGE_URI not set. Exiting ....'\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [ -z \"$1\" ]\n",
    "  then\n",
    "    MODEL_REPOSITORY=/model\n",
    "  else\n",
    "    MODEL_REPOSITORY=$1\n",
    "fi\n",
    "\n",
    "echo \"Copying model ensemble from ${AIP_STORAGE_URI} to ${MODEL_REPOSITORY}\"\n",
    "mkdir ${MODEL_REPOSITORY} \n",
    "gsutil -m cp -r ${AIP_STORAGE_URI}/* ${MODEL_REPOSITORY}\n",
    "\n",
    "# gsutil does not copy empty dirs so create a version folder for the ensemble\n",
    "ENSEMBLE_DIR=$(ls ${MODEL_REPOSITORY} | grep ens)\n",
    "mkdir ${MODEL_REPOSITORY}/${ENSEMBLE_DIR}/1 \n",
    "export LD_LIBRARY_PATH=/usr/local/lib:${LD_LIBRARY_PATH}\n",
    "\n",
    "echo \"Starting Triton Server\"\n",
    "LD_PRELOAD=/usr/local/lib/libarrow.so tritonserver --model-repository=$MODEL_REPOSITORY --backend-config=pytorch,shm-default-byte-size=67108864 --vertex-ai-default-model=0_predictpytorchtriton --strict-model-config=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "bdcf8486-886a-4d34-b1f3-7ec5a972158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Dockerfile.servet4rec-tr\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{DOCKERNAME}\n",
    "\n",
    "FROM nvcr.io/nvidia/tritonserver:23.01-py3 \n",
    "# AS triton\n",
    "# FROM nvcr.io/nvidia/merlin/merlin-pytorch:22.12\n",
    "\n",
    "EXPOSE 8000\n",
    "EXPOSE 8001\n",
    "EXPOSE 8002\n",
    "\n",
    "WORKDIR /src\n",
    "\n",
    "# Copies the serving code to the docker image.\n",
    "COPY serving/* serving/ \n",
    "\n",
    "RUN pip3 install -U pip\n",
    "RUN pip3 install -r serving/requirements.txt\n",
    "# RUN pip3 install google-cloud-aiplatform\n",
    "# RUN pip3 install transformers\n",
    "# RUN pip3 install transformers4rec[pytorch,nvtabular,dataloader]\n",
    "RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && apt-get update -y && apt-get install google-cloud-sdk -y\n",
    "\n",
    "COPY serving/entrypoint.sh ./\n",
    "RUN chmod +x entrypoint.sh\n",
    "\n",
    "ENTRYPOINT [\"./entrypoint.sh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1132ff90-de6b-48a6-ba60-1a3f81b1cad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/requirements.txt\n",
    "google-cloud-aiplatform==1.21.0\n",
    "transformers4rec[pytorch,nvtabular,dataloader]\n",
    "google-api-core==2.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ab707b46-d610-46ff-ae15-60dc2150b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE_TYPE: e2-highcpu-32\n",
      "FILE_LOCATION: ./src\n"
     ]
    }
   ],
   "source": [
    "# cloud build\n",
    "MACHINE_TYPE ='e2-highcpu-32'\n",
    "FILE_LOCATION = f'./{REPO_DOCKER_PATH_PREFIX}'\n",
    "\n",
    "print(f\"MACHINE_TYPE: {MACHINE_TYPE}\")\n",
    "print(f\"FILE_LOCATION: {FILE_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b71f1-37d8-42c7-8f6f-b2528206d3bc",
   "metadata": {},
   "source": [
    "### gcloud ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "50264fa3-3b69-4229-bb9d-407719775be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0302 20:14:29.750621465   21009 backup_poller.cc:134]       Run client channel backup poller: {\"created\":\"@1677788069.750435173\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":320,\"referenced_errors\":[{\"created\":\"@1677788069.750417091\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":950,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "Updated property [gcloudignore/enabled].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set gcloudignore/enabled true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3c49f2df-2046-4748-a724-5ee620271c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .gcloudignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gcloudignore\n",
    ".gcloudignore\n",
    "/categories/\n",
    "/tmp/\n",
    "/workspace/\n",
    "/torch_ensemble/\n",
    "/workspace_v3/\n",
    "/local_model_artifacts/\n",
    "/workspace_v2/\n",
    "/testing_entry/\n",
    "*.ipynb\n",
    "*.parquet\n",
    ".git\n",
    ".github\n",
    ".ipynb_checkpoints/*\n",
    "*__pycache__\n",
    "*cpython-37.pyc\n",
    "data_utils.py\n",
    "t4rec_payload.json\n",
    "single_t4rec_payload.json\n",
    "credentials.json\n",
    "instances.json\n",
    "payload_ensemble.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "1978d89e-779a-4112-84c5-613338f367e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/cloudbuild.yaml\n",
      "src/Dockerfile.servet4rec-tr\n",
      "src/serving/entrypoint.sh\n",
      "src/serving/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df4ae0-1398-4417-a7c1-19553b346db0",
   "metadata": {},
   "source": [
    "## submit image to Cloud Build\n",
    "\n",
    "* run in notebook terminal or in notebook cell/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "99c1c18d-a3c8-405e-86bc-5ed139ee9dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DOCKERNAME=servet4rec-tr\n",
    "# IMAGE_URI=gcr.io/hybrid-vertex/triton-0_predictpytorchtriton-v03\n",
    "# FILE_LOCATION=./src\n",
    "# MACHINE_TYPE=e2-highcpu-32\n",
    "\n",
    "# gcloud builds submit --config src/cloudbuild.yaml \\\n",
    "#     --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "#     --timeout=2h \\\n",
    "#     --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dafb2d-e3a5-44c5-97e8-dab2d90505a4",
   "metadata": {},
   "source": [
    "# Create Vertex AI Model resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad3572-1c72-4b12-a40b-6b60413be73f",
   "metadata": {},
   "source": [
    "* see [Triton protocol](https://github.com/kserve/kserve/blob/master/docs/predict-api/v2/required_api.md#inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92475b-7784-4844-a9b1-a58f85fce23a",
   "metadata": {},
   "source": [
    "## credentials\n",
    "\n",
    "if running into IAM issues from notebook instance, run these in noteboook terminal..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462035b-bbd7-4ec0-9010-fee4dcef5fd0",
   "metadata": {},
   "source": [
    "#### [1] application_default_credentials\n",
    "* creates file e.g.,: `[/root/.config/gcloud/application_default_credentials.json]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9ba19604-8eb1-42d8-9a85-0ef5bb8fd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62206976-1bdf-4e40-ad9c-b3ec2ce98510",
   "metadata": {},
   "source": [
    "#### [2] set service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "192f7b0b-c483-43f0-ad2b-deaafe4ce5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERTEX_SA = 'jt-vertex-sa@hybrid-vertex.iam.gserviceaccount.com'\n",
    "# !gcloud config set account $VERTEX_SA`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be88007-b83d-4595-9b2d-3cc12ba69ab1",
   "metadata": {},
   "source": [
    "#### [3] grant SA permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "b70e4652-6022-4519-afc6-996996245d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#     --member=serviceAccount:$VERTEX_SA \\\n",
    "#     --role=roles/storage.objectViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653aacd1-747f-469a-a7d4-4dc0f020e7df",
   "metadata": {},
   "source": [
    "#### get credentials config for SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee406ee6-3021-4aab-86ac-cc21c0a03fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created key [90365f8890abbc778a4299ac9998342dea811f4d] of type [json] as [./credentials.json] for [jt-vertex-sa@hybrid-vertex.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "# CREDENTIALS_FILE = \"./credentials.json\"\n",
    "\n",
    "# !gcloud iam service-accounts keys create $CREDENTIALS_FILE \\\n",
    "#     --iam-account=$VERTEX_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "458900bf-5d58-486f-956c-6403029c8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "# t4rec-nvidia-docs/credentials.json\n",
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950bd0c-a7aa-4bd1-a922-130db05f95c3",
   "metadata": {},
   "source": [
    "### triton credentials\n",
    "\n",
    "* TODO\n",
    "* see [model_repository user guide](https://github.com/triton-inference-server/server/blob/main/docs/user_guide/model_repository.md#cloud-storage-with-environment-variables) re: GCS environment variables and `TRITON_CLOUD_CREDENTIAL_PATH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "467d37aa-7a82-4dba-a1e4-3c90150a0cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud storage cp credentials.json $BUCKET_URI/$MODEL_VERSION/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "48fd4e73-1a4e-468f-b7a4-0833bc0690ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud storage cp /root/.config/gcloud/application_default_credentials.json $BUCKET_URI/$MODEL_VERSION/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e32d9-dafa-42da-b82b-1e0abfc887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/cloud_credential.json\n",
    "# {\n",
    "#   \"gs\": {\n",
    "#     \"\": \"PATH_TO_GOOGLE_APPLICATION_CREDENTIALS\",\n",
    "#     \"gs://gcs-bucket-002\": \"PATH_TO_GOOGLE_APPLICATION_CREDENTIALS_2\"\n",
    "#   },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc000c04-d3a9-4a09-9043-ea0b66369ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs://merlin-transformers4rec-jvt01/v02/credentials.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c960756-ffeb-4f76-8615-a3d26c4ffe59",
   "metadata": {},
   "source": [
    "## upload model to Vertex Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "44db18f1-3890-459c-b2d0-e6e2135f68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID, \n",
    "    location=REGION,\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "937fad44-65c7-40a9-a547-bc860054af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DISPLAY_NAME = triton-0_predictpytorchtriton-v03\n",
      "IMAGE_URI = gcr.io/hybrid-vertex/triton-0_predictpytorchtriton-v03\n",
      "MODEL_ARTIFACTS_REPO_GCS = gs://merlin-transformers4rec-jvt02/v03/workspace/data/models\n",
      "MODEL_NAME = 0_predictpytorchtriton\n"
     ]
    }
   ],
   "source": [
    "print(f\"MODEL_DISPLAY_NAME = {MODEL_DISPLAY_NAME}\")\n",
    "print(f\"IMAGE_URI = {IMAGE_URI}\")\n",
    "print(f\"MODEL_ARTIFACTS_REPO_GCS = {MODEL_ARTIFACTS_REPO_GCS}\")\n",
    "print(f\"MODEL_NAME = {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "92f32679-8ec1-4e08-a03f-6e0f878a74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/4362072689666424832/operations/676066404016848896\n",
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/4362072689666424832@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/4362072689666424832@1')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/models/4362072689666424832'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVING_CONTAINER_ARGS = ['/models']\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "    display_name=f'{MODEL_DISPLAY_NAME}',\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    artifact_uri=MODEL_ARTIFACTS_REPO_GCS,\n",
    "    credentials=credentials,\n",
    "    serving_container_args=SERVING_CONTAINER_ARGS,\n",
    "        # \"tritonserver\",  # tritonserver | triton\n",
    "        # \"--model-repository=$(AIP_STORAGE_URI)\"\n",
    "        # \"--backend-config=python,shm-default-byte-size=4194304\", # 4194304\n",
    "        # f\"--vertex-ai-default-model={MODEL_NAME}\", # ensemble | {MODEL_NAME}\n",
    "        # \"--strict-model-config=true\",\n",
    "        # \"--log-verbose=99\",\n",
    "        # \"--log-error=1\",\n",
    "    # ],\n",
    "    # serving_container_health_route=f\"/v2/models/{MODEL_NAME}\",        # \"/health\",\n",
    "    # serving_container_predict_route=f\"/v2/models/{MODEL_NAME}/infer\", #\"/predict\",\n",
    "    # serving_container_ports=[8080],\n",
    "    # serving_container_environment_variables=\n",
    "    # labels={\"key\": \"value\", \"key_2\": \"value_2\"},\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "\n",
    "# model = aip.Model('projects/934903580331/locations/us-central1/models/2389777527854858240@1')\n",
    "\n",
    "model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44524c4b-4abf-4c47-ba26-6540fe2f9aa4",
   "metadata": {},
   "source": [
    "## Create Model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "bef1bfbe-2316-4c98-99ee-e9e05a360039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/2776763839390154752/operations/3898391937400438784\n",
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/2776763839390154752\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/2776763839390154752')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/endpoints/2776763839390154752'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=f'{ENDPOINT_DISPLAY_NAME}-v2',\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    # enable_request_response_logging=True\n",
    ")\n",
    "\n",
    "# endpoint = aip.Endpoint('projects/934903580331/locations/us-central1/endpoints/4659549958607732736')\n",
    "\n",
    "endpoint.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff791a-5f68-4dbf-ae76-f001c37a9241",
   "metadata": {},
   "source": [
    "## deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ba0e1e74-f553-4505-bd7c-c4f5ffda7d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/2776763839390154752\n",
      "Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/2776763839390154752/operations/5472400007166427136\n",
      "Endpoint model deployed. Resource name: projects/934903580331/locations/us-central1/endpoints/2776763839390154752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7fe0b0108220> \n",
       "resource name: projects/934903580331/locations/us-central1/endpoints/2776763839390154752"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-highmem-16\"\n",
    "accelerator_type = \"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "min_replica_count = 1\n",
    "max_replica_count = 1\n",
    "# DEPLOYED_MODEL_DISPLAY_NAME = 'deployed-triton-t4r-v3'\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=f'{DEPLOYED_MODEL_DISPLAY_NAME}-v2',\n",
    "    machine_type=machine_type,\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    service_account=VERTEX_SA,\n",
    "    sync=True,\n",
    "    # deploy_request_timeout=1800\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e4f4b-8a2a-4adc-9411-852be85d1fff",
   "metadata": {},
   "source": [
    "# clean-up helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bb697-0f68-4a9a-b3ed-072497adadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex_ai.Endpoint.delete(endpoint)\n",
    "# vertex_ai.Model.delete(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
